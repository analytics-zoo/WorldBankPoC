{"cells":[{"cell_type":"code","source":["##sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", ACCESS_KEY)\n# sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", \"\")\n##sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", SECRET_KEY)\n#sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", \"\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import pandas as pd\nfrom os import listdir\nfrom os.path import join, basename\nimport struct\nimport pickle\nimport json\nimport os\nfrom scipy import misc\nimport datetime as dt\nimport time\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline\n# import matplotlib.pyplot as plt\n# %matplotlib inline"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# %pylab inline\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom zoo.pipeline.nnframes.nn_image_reader import *\nfrom zoo.feature.common import *\nfrom zoo.feature.image.imagePreprocessing import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.pipeline.api.keras.layers import Dense, Input, Flatten\nfrom zoo.pipeline.api.keras.models import *\nfrom zoo.pipeline.api.net import *\nfrom zoo.common.nncontext import *\nimport urllib\nfrom os import path"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["\ndef scala_T(input_T):\n    \"\"\"\n    Helper function for building Inception layers. Transforms a list of numbers to a dictionary with ascending keys \n    and 0 appended to the front. Ignores dictionary inputs. \n    \n    :param input_T: either list or dict\n    :return: dictionary with ascending keys and 0 appended to front {0: 0, 1: realdata_1, 2: realdata_2, ...}\n    \"\"\"    \n    if type(input_T) is list:\n        # insert 0 into first index spot, such that the real data starts from index 1\n        temp = [0]\n        temp.extend(input_T)\n        return dict(enumerate(temp))\n    # if dictionary, return it back\n    return input_T"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def Inception_Layer_v1(input_size, config, name_prefix=\"\"):\n    \"\"\"\n    Builds the inception-v1 submodule, a local network, that is stacked in the entire architecture when building\n    the full model.  \n    \n    :param input_size: dimensions of input coming into the local network\n    :param config: ?\n    :param name_prefix: string naming the layers of the particular local network\n    :return: concat container object with all of the Sequential layers' ouput concatenated depthwise\n    \"\"\"        \n    \n    '''\n    Concat is a container who concatenates the output of it's submodules along the provided dimension: all submodules \n    take the same inputs, and their output is concatenated.\n    '''\n    concat = Concat(2)\n    \n    \"\"\"\n    In the above code, we first create a container Sequential. Then add the layers into the container one by one. The \n    order of the layers in the model is same with the insertion order. \n    \n    \"\"\"\n    conv1 = Sequential()\n    \n    #Adding layes to the conv1 model we jus created\n    \n    #SpatialConvolution is a module that applies a 2D convolution over an input image.\n    conv1.add(SpatialConvolution(input_size, config[1][1], 1, 1, 1, 1).set_name(name_prefix + \"1x1\"))\n    conv1.add(ReLU(True).set_name(name_prefix + \"relu_1x1\"))\n    concat.add(conv1)\n    \n    conv3 = Sequential()\n    conv3.add(SpatialConvolution(input_size, config[2][1], 1, 1, 1, 1).set_name(name_prefix + \"3x3_reduce\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3_reduce\"))\n    conv3.add(SpatialConvolution(config[2][1], config[2][2], 3, 3, 1, 1, 1, 1).set_name(name_prefix + \"3x3\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3\"))\n    concat.add(conv3)\n    \n    \n    conv5 = Sequential()\n    conv5.add(SpatialConvolution(input_size,config[3][1], 1, 1, 1, 1).set_name(name_prefix + \"5x5_reduce\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5_reduce\"))\n    conv5.add(SpatialConvolution(config[3][1], config[3][2], 5, 5, 1, 1, 2, 2).set_name(name_prefix + \"5x5\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5\"))\n    concat.add(conv5)\n    \n    \n    pool = Sequential()\n    pool.add(SpatialMaxPooling(3, 3, 1, 1, 1, 1, to_ceil=True).set_name(name_prefix + \"pool\"))\n    pool.add(SpatialConvolution(input_size, config[4][1], 1, 1, 1, 1).set_name(name_prefix + \"pool_proj\"))\n    pool.add(ReLU(True).set_name(name_prefix + \"relu_pool_proj\"))\n    concat.add(pool).set_name(name_prefix + \"output\")\n    return concat"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["def Inception_v1(class_num):\n    model = Sequential()\n    model.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False).set_name(\"conv1/7x7_s2\"))\n    model.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n    model.add(SpatialConvolution(64, 64, 1, 1, 1, 1).set_name(\"conv2/3x3_reduce\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n    model.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1).set_name(\"conv2/3x3\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n    model.add(Inception_Layer_v1(192, scala_T([scala_T([64]), scala_T(\n         [96, 128]), scala_T([16, 32]), scala_T([32])]), \"inception_3a/\"))\n    model.add(Inception_Layer_v1(256, scala_T([scala_T([128]), scala_T(\n         [128, 192]), scala_T([32, 96]), scala_T([64])]), \"inception_3b/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(Inception_Layer_v1(480, scala_T([scala_T([192]), scala_T(\n         [96, 208]), scala_T([16, 48]), scala_T([64])]), \"inception_4a/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([160]), scala_T(\n         [112, 224]), scala_T([24, 64]), scala_T([64])]), \"inception_4b/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([128]), scala_T(\n         [128, 256]), scala_T([24, 64]), scala_T([64])]), \"inception_4c/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([112]), scala_T(\n         [144, 288]), scala_T([32, 64]), scala_T([64])]), \"inception_4d/\"))\n    model.add(Inception_Layer_v1(528, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_4e/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(Inception_Layer_v1(832, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_5a/\"))\n    model.add(Inception_Layer_v1(832, scala_T([scala_T([384]), scala_T(\n         [192, 384]), scala_T([48, 128]), scala_T([128])]), \"inception_5b/\"))\n    model.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n    model.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n    model.add(View([1024], num_input_dims=3))\n    model.add(Linear(1024, class_num).set_name(\"loss3/classifier\"))\n    model.add(LogSoftMax().set_name(\"loss3/loss3\"))\n    model.reset()\n    return model"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from os import path\nDATA_ROOT = \"/mnt/nobigdl/vegnonveg-full/\"\nMODEL_ROOT = \"/mnt/nobigdl/models/inceptionv1/\"\ndbutils.fs.mkdirs(MODEL_ROOT)\ncheckpoint_path = path.join(MODEL_ROOT, \"checkpoints\")\nimage_path = DATA_ROOT + \"pictures/\"\nlabel_path = DATA_ROOT + \"labels/vegnonveg-full_labels.csv\"\nparquet_path = DATA_ROOT + \"vegnonveg-full_parquet/\"\n#parquet_path = DATA_ROOT + \"parquet/\"\n# dbutils.fs.rm(parquet_path, True)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## Initialize BigDL\n\nInitialize BigDL and re-direct Spark logs"],"metadata":{}},{"cell_type":"code","source":["#intialize bigdl\ninit_engine()\nredire_spark_logs()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["## Read images to parquet file and load to Spark as Image dataframe\n\nSave data to parquet files and load to Spark. Add label to each image."],"metadata":{}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/nobigdl/vegnonveg-full/labels\"))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["## Option 1 for image loading: use directory path\n# image_path = \"/mnt/nobigdl/vegnonveg-full/pictures/*\""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["## Option 2 for image loading: concatenate file paths\n# image_path = \"/mnt/nobigdl/datasets/vegnonveg/pictures/44226b66-6fdc-440d-a850-63073bdf9682,/mnt/nobigdl/datasets/vegnonveg/pictures/44226b66-6fdc-440d-a850-63073bdf9682\""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["## This only runs at the first time to generate parquet files\n# image_frame = NNImageReader.readImages(image_path, sc, minParitions=32)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# labels_csv = pd.read_csv(\"/dbfs/mnt/nobigdl/vegnonveg-full/labels/vegnonveg-full_labels.csv\")\n# s3_uris = labels_csv[\"s3_uri\"].tolist()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# s3_uri_str = ','.join(s3_uris)\n# image_frame = NNImageReader.readImages(s3_uri_str, sc, minPartitions=32)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#save dataframe to parquet files\n# image_frame.write.parquet(parquet_path)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# load parquet file into Spark cluster\nimport time\nstart = time.time()\nimage_raw_DF = sqlContext.read.parquet(parquet_path)\n# image1 = image_raw_DF.take(1)\n# print(image1[0])\nend = time.time()\nprint(\"Load data time is: \" + str(end-start) + \" seconds\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# print(image_raw_DF.count())"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# create dict from label to numeric label\nlabels_csv = pd.read_csv(\"/dbfs\"+label_path)\nunique_labels = labels_csv[\"label\"].unique().tolist()\nlabel_dict = dict(zip(unique_labels, range(1,len(unique_labels)+1)))\nlabel_dict\nlen(label_dict)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# image_names = [uri.split(\"/\")[-1] for uri in labels_csv[\"s3_uri\"].tolist()]\n# labels = labels_csv[\"label\"].tolist()\n# name_dict = dict(zip(image_names, [label_dict[code] for code in labels]))\n# name_dict\n# len(image_names)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# See https://spark.apache.org/docs/latest/sql-programming-guide.html#broadcast-hint-for-sql-queries\n  \n# create label dataframe\nlabel_raw_DF = sqlContext.read.format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .option(\"mode\", \"DROPMALFORMED\")\\\n    .load(label_path)\\\n    .na.drop()\n# label_raw_DF.show()    \nget_label = udf(lambda label: float(label_dict[label]), FloatType())\nchange_name = udf(lambda uid: uid+\".jpg\", StringType())\nlabelDF = label_raw_DF.withColumn(\"label\", get_label(\"label\")).withColumn(\"image_name\", change_name(\"obs_uid\"))\n# labelDF = label_raw_DF.withColumn(\"label\", get_label(\"label\"))\nlabelDF.show(truncate=False)\n# print(labelDF.count())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# create image data dataframe\nget_name = udf(lambda row: row[0].split(\"/\")[-1], StringType())\n# get_label = udf(lambda name: float(name_dict[name]), FloatType())\nimageDF = image_raw_DF.withColumn(\"image_name\", get_name(\"image\"))\n# imageDF.show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["from pyspark.sql.functions import col, broadcast\n# image dataframe join with labels\ndataDF = imageDF.join(broadcast(labelDF), \"image_name\", \"inner\").select(\"image\", 'image_name', \"label\")\n# dataDF.select(\"image_name\", \"label\").show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# print(dataDF.count())"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["## Do Train/Test Split and preprocessing\nSplit Train/Test split with some ratio and preprocess images."],"metadata":{}},{"cell_type":"code","source":["data = dataDF.randomSplit([0.8, 0.1, 0.1], seed=10)\ntrain_image = data[0]\nval_image = data[1]\ntest_image = data[2]\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["IMAGE_SIZE = 224\ntrain_transformer = ChainedPreprocessing(\n        [RowToImageFeature(), ImageResize(256, 256), ImageCenterCrop(IMAGE_SIZE, IMAGE_SIZE),\n         ImageChannelNormalize(123.0, 117.0, 104.0), ImageMatToTensor(), ImageFeatureToTensor()])\n\n"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# train_size = train_image.count()\n# train_size"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["## Define Model"],"metadata":{}},{"cell_type":"code","source":["# Parameters\nlearning_rate = 0.06\n# parameters for \nbatch_size = 1200 #depends on dataset and cluster config (e.g. 16 nodes * 30-cores * 2 images each)\nno_epochs = 12 #stop when validation accuracy doesn't improve anymore\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# get model\npretrained_model_path = path.join(MODEL_ROOT,\"bigdl_inception_v1_imagenet_0_4_0.model\")\nn_classes = len(label_dict)# label categories\nfull_model = Net.load_bigdl(\"dbfs:\" + pretrained_model_path)\n# create a new model by remove layers after pool5/drop_7x7_s1\nmodel = full_model.new_graph([\"pool5/drop_7x7_s1\"])\n\ninputNode = Input(name=\"input\", shape=(3, 224, 224))\ninception = model.to_keras()(inputNode)\nflatten = Flatten()(inception)\nlogits = Dense(n_classes)(flatten)\n\nlrModel = Model(inputNode, logits)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# train model\nclassifier = NNClassifier(lrModel, CrossEntropyCriterion(), train_transformer) \\\n        .setLearningRate(learning_rate)\\\n        .setBatchSize(batch_size)\\\n        .setMaxEpoch(no_epochs)\\\n        .setFeaturesCol(\"image\")\\\n        .setValidation(EveryEpoch(), val_image, [Top1Accuracy()], batch_size)\nstart = time.time()\ntrained_model = classifier.fit(train_image)\nend = time.time()\nprint(\"Optimization Done.\")\nprint(\"Training time is: %s seconds\" % str(end-start))\n# + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["trained_model.save((\"/dbfs\" + path.join(MODEL_ROOT, \"model_finetune\")), True)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["train_size = 795052\nthroughput = train_size * no_epochs / (end - start)\nprint(\"Average throughput is: %s\" % str(throughput))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#predict\npredict_model = trained_model.setBatchSize(batch_size)\npredictionDF = predict_model.transform(test_image)\npredictionDF.cache()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["predictionDF.show()\n"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["predictionDF.select(\"image_name\", \"label\", \"prediction\").coalesce(1).write.format('csv').options(header='true', delimiter = ',').save('/mnt/nobigdl/vegnonveg-full/labels/predicted_labels-20180603.csv')"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# num_preds = 1\n# preds = predictionDF.select(\"label\", \"prediction\").take(num_preds)\n# for idx in range(num_preds):\n# #    true_label = str(map_to_label(map_groundtruth_label(truth[idx].label)))\n#     true_label = preds[idx][0]\n#     pred_label = preds[idx][1]\n#     print(str(idx + 1) +')'+ 'Ground Truth label: '+ str(true_label))\n#     print(str(idx + 1) + ')'+ 'Predicted label: '+ str(pred_label))\n#     print(\"correct\" if true_label == pred_label else \"wrong\")"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["'''\nMeasure Test Accuracy w/Test Set\n'''\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n                                              predictionCol=\"prediction\",\n                                              metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictionDF)\n# expected error should be less than 10%\nprint(\"Accuracy = %g \" % accuracy)\npredictionDF.unpersist()"],"metadata":{},"outputs":[],"execution_count":40}],"metadata":{"name":"vegnonveg-fulltraining-nnframe","notebookId":230917782772627},"nbformat":4,"nbformat_minor":0}
