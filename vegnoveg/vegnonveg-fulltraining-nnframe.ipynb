{"cells":[{"cell_type":"code","source":["import pandas as pd\nfrom os import listdir\nfrom os.path import join, basename\nimport struct\nimport pickle\nimport json\nimport os\nfrom scipy import misc\nimport datetime as dt\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n# import matplotlib.pyplot as plt\n# %matplotlib inline"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# %pylab inline\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\nfrom bigdl.dataset.transformer import *\nfrom bigdl.dataset import mnist\nfrom bigdl.transform.vision.image import *\nfrom zoo.pipeline.nnframes.nn_image_reader import *\nfrom zoo.pipeline.nnframes.nn_image_transformer import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.common.nncontext import *\nimport urllib\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["\ndef scala_T(input_T):\n    \"\"\"\n    Helper function for building Inception layers. Transforms a list of numbers to a dictionary with ascending keys \n    and 0 appended to the front. Ignores dictionary inputs. \n    \n    :param input_T: either list or dict\n    :return: dictionary with ascending keys and 0 appended to front {0: 0, 1: realdata_1, 2: realdata_2, ...}\n    \"\"\"    \n    if type(input_T) is list:\n        # insert 0 into first index spot, such that the real data starts from index 1\n        temp = [0]\n        temp.extend(input_T)\n        return dict(enumerate(temp))\n    # if dictionary, return it back\n    return input_T"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def Inception_Layer_v1(input_size, config, name_prefix=\"\"):\n    \"\"\"\n    Builds the inception-v1 submodule, a local network, that is stacked in the entire architecture when building\n    the full model.  \n    \n    :param input_size: dimensions of input coming into the local network\n    :param config: ?\n    :param name_prefix: string naming the layers of the particular local network\n    :return: concat container object with all of the Sequential layers' ouput concatenated depthwise\n    \"\"\"        \n    \n    '''\n    Concat is a container who concatenates the output of it's submodules along the provided dimension: all submodules \n    take the same inputs, and their output is concatenated.\n    '''\n    concat = Concat(2)\n    \n    \"\"\"\n    In the above code, we first create a container Sequential. Then add the layers into the container one by one. The \n    order of the layers in the model is same with the insertion order. \n    \n    \"\"\"\n    conv1 = Sequential()\n    \n    #Adding layes to the conv1 model we jus created\n    \n    #SpatialConvolution is a module that applies a 2D convolution over an input image.\n    conv1.add(SpatialConvolution(input_size, config[1][1], 1, 1, 1, 1).set_name(name_prefix + \"1x1\"))\n    conv1.add(ReLU(True).set_name(name_prefix + \"relu_1x1\"))\n    concat.add(conv1)\n    \n    conv3 = Sequential()\n    conv3.add(SpatialConvolution(input_size, config[2][1], 1, 1, 1, 1).set_name(name_prefix + \"3x3_reduce\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3_reduce\"))\n    conv3.add(SpatialConvolution(config[2][1], config[2][2], 3, 3, 1, 1, 1, 1).set_name(name_prefix + \"3x3\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3\"))\n    concat.add(conv3)\n    \n    \n    conv5 = Sequential()\n    conv5.add(SpatialConvolution(input_size,config[3][1], 1, 1, 1, 1).set_name(name_prefix + \"5x5_reduce\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5_reduce\"))\n    conv5.add(SpatialConvolution(config[3][1], config[3][2], 5, 5, 1, 1, 2, 2).set_name(name_prefix + \"5x5\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5\"))\n    concat.add(conv5)\n    \n    \n    pool = Sequential()\n    pool.add(SpatialMaxPooling(3, 3, 1, 1, 1, 1, to_ceil=True).set_name(name_prefix + \"pool\"))\n    pool.add(SpatialConvolution(input_size, config[4][1], 1, 1, 1, 1).set_name(name_prefix + \"pool_proj\"))\n    pool.add(ReLU(True).set_name(name_prefix + \"relu_pool_proj\"))\n    concat.add(pool).set_name(name_prefix + \"output\")\n    return concat"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def Inception_v1(class_num):\n    model = Sequential()\n    model.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False).set_name(\"conv1/7x7_s2\"))\n    model.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n    model.add(SpatialConvolution(64, 64, 1, 1, 1, 1).set_name(\"conv2/3x3_reduce\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n    model.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1).set_name(\"conv2/3x3\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n    model.add(Inception_Layer_v1(192, scala_T([scala_T([64]), scala_T(\n         [96, 128]), scala_T([16, 32]), scala_T([32])]), \"inception_3a/\"))\n    model.add(Inception_Layer_v1(256, scala_T([scala_T([128]), scala_T(\n         [128, 192]), scala_T([32, 96]), scala_T([64])]), \"inception_3b/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(Inception_Layer_v1(480, scala_T([scala_T([192]), scala_T(\n         [96, 208]), scala_T([16, 48]), scala_T([64])]), \"inception_4a/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([160]), scala_T(\n         [112, 224]), scala_T([24, 64]), scala_T([64])]), \"inception_4b/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([128]), scala_T(\n         [128, 256]), scala_T([24, 64]), scala_T([64])]), \"inception_4c/\"))\n    model.add(Inception_Layer_v1(512, scala_T([scala_T([112]), scala_T(\n         [144, 288]), scala_T([32, 64]), scala_T([64])]), \"inception_4d/\"))\n    model.add(Inception_Layer_v1(528, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_4e/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(Inception_Layer_v1(832, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_5a/\"))\n    model.add(Inception_Layer_v1(832, scala_T([scala_T([384]), scala_T(\n         [192, 384]), scala_T([48, 128]), scala_T([128])]), \"inception_5b/\"))\n    model.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n    model.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n    model.add(View([1024], num_input_dims=3))\n    model.add(Linear(1024, class_num).set_name(\"loss3/classifier\"))\n    model.add(LogSoftMax().set_name(\"loss3/loss3\"))\n    model.reset()\n    return model"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## Download the images from Amazon s3\n\nMake sure you have AWS command line interface to recursively download all images in s3 folder. You can set up aws cli from this link: http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html"],"metadata":{}},{"cell_type":"code","source":["import urllib\nfrom os import path\nMODEL_ROOT = \"/mnt/nobigdl/few-inceptionv1\"\n# dbutils.fs.mkdirs(MODEL_ROOT)\n#local_folder = DATA_ROOT + '/vegnonveg-samples'\ncheckpoint_path = path.join(MODEL_ROOT, \"checkpoints\")\n\n# if not path.isdir(local_folder):\n#   os.system('aws s3 cp --recursive s3://vegnonveg/vegnonveg-fewsamples %s' % local_folder)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## Read images to parquet fileand load to Spark as Image dataframe\n\nsave data to parquet files and load to spark. Add label to each image."],"metadata":{}},{"cell_type":"code","source":["DATA_ROOT = \"/mnt/nobigdl/vegnonveg/python/inception_v1/sample_images/\"\nsample_path = DATA_ROOT + 'vegnonveg-fewsamples/'\n# sample_path = '/mnt/nobigdl/vegnonveg-samples100/'\nlabel_path = DATA_ROOT + 'vegnonveg-samples_labels.csv'\nparquet_path = DATA_ROOT + 'sample_parquet/'\n# dbutils.fs.rm(parquet_path, True)\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#intializa bigdl\ninit_engine()\nredire_spark_logs()\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# This only runs at the first time to generate parquet files\nimage_frame = NNImageReader.readImages(sample_path, sc, minParitions=32)\n# save dataframe to parquet files\nimage_frame.write.parquet(parquet_path)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# load parquet file into spark cluster\nimport time\nstart = time.time()\nimage_raw_DF = sqlContext.read.parquet(parquet_path)\nend = time.time()\nprint(\"Load data time is: \" + str(end-start) + \" seconds\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# create dict from item_name to label\nlabels_csv = pd.read_csv(\"/dbfs\"+label_path)\nunique_labels = labels_csv['item_name'].unique().tolist()\nlabel_dict = dict(zip(unique_labels, range(1,len(unique_labels)+1)))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# create label dataframe\nlabel_raw_DF = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"mode\", \"DROPMALFORMED\")\\\n    .load(label_path)\nget_label = udf(lambda item_name: float(label_dict[item_name]), FloatType())\n# change_name = udf(lambda uid: uid+\".jpg\", StringType())\n# labelDF = label_raw_DF.withColumn(\"label\", get_label(\"item_name\")).withColumn(\"image_name\", change_name(\"obs_uid\"))\nlabelDF = label_raw_DF.withColumn(\"label\", get_label(\"item_name\"))\nlabelDF.show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# create image data dataframe\nget_name = udf(lambda row: row[0].split(\"/\")[-1], StringType())\nimageDF = image_frame.withColumn(\"image_name\", get_name(\"image\"))\nimageDF.show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# image dataframe join with labels\n# dataDF = imageDF.join(labelDF, \"image_name\", \"inner\").select(\"image\", \"image_name\", \"label\")\ndataDF = imageDF.join(labelDF, imageDF.image_name==labelDF.obs_uid, \"inner\").select(\"image\", \"image_name\", \"label\")\ndataDF.show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Do Train/Test Split and preprocessing\nSplit Train/Test split with some ratio and preprocess images."],"metadata":{}},{"cell_type":"code","source":["data = dataDF.randomSplit([0.8, 0.2], seed=10)\ntrain_image = data[0]\nval_image = data[1]"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["IMAGE_SIZE = 224\n\ntrain_transformer = NNImageTransformer(\n    Pipeline([Resize(256, 256), RandomCrop(IMAGE_SIZE, IMAGE_SIZE),\n              ChannelNormalize(123.0, 117.0, 104.0, 1.0, 1.0, 1.0),\n              MatToTensor()])\n).setInputCol(\"image\").setOutputCol(\"features\")\n\ntrain_data = train_transformer.transform(train_image)\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["train_size = train_image.count()\ntrain_size"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["val_transformer = NNImageTransformer(\n    Pipeline([Resize(256,256),\n              CenterCrop(IMAGE_SIZE, IMAGE_SIZE),\n              ChannelNormalize(123.0, 117.0, 104.0, 1.0, 1.0, 1.0),\n              MatToTensor(to_rgb=True)]\n            )\n).setInputCol(\"image\").setOutputCol(\"features\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["test_data = val_transformer.transform(val_image)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["## Define Model"],"metadata":{}},{"cell_type":"code","source":["# Network Parameters\nn_classes = len(label_dict)# item_name categories\nmodel = Inception_v1(n_classes)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Parameters\nlearning_rate = 0.2\n# parameters for \nbatch_size = 64 #depends on dataset\nno_epochs = 1 #stop when validation accuracy doesn't improve anymore"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["criterion = ClassNLLCriterion()\nclassifier = NNClassifier(model, criterion, [3,IMAGE_SIZE,IMAGE_SIZE])\\\n    .setBatchSize(batch_size)\\\n    .setMaxEpoch(no_epochs)\\\n    .setLearningRate(learning_rate)\nstart = time.time()\ntrained_model = classifier.fit(train_data)\nend = time.time()\nprint(\"Optimization Done.\")\nprint(\"Training time is: %s seconds\" % str(end-start))\n# + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["throughput = train_size * no_epochs / (end - start)\nprint(\"Average throughput is: %s\" % str(throughput))"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#predict\npredict_model = trained_model.setBatchSize(batch_size)\npredictionDF = predict_model.transform(test_data)\npredictionDF.show()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["num_preds = 1\npreds = predictionDF.select(\"label\", \"prediction\").take(num_preds)\nfor idx in range(num_preds):\n#    true_label = str(map_to_label(map_groundtruth_label(truth[idx].label)))\n    true_label = preds[idx][0]\n    pred_label = preds[idx][1]\n    print(str(idx + 1) +')'+ 'Ground Truth label: '+ str(true_label))\n    print(str(idx + 1) + ')'+ 'Predicted label: '+ str(pred_label))\n    print(\"correct\" if true_label == pred_label else \"wrong\")"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["'''\nMeasure Test Accuracy w/Test Set\n'''\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictionDF)\n# expected error should be less than 10%\nprint(\"Accuracy = %g \" % accuracy)"],"metadata":{},"outputs":[],"execution_count":30}],"metadata":{"name":"vegnonveg-fulltraining-nnframe","notebookId":1311655684254361},"nbformat":4,"nbformat_minor":0}
