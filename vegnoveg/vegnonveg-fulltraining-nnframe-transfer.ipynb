{"cells":[{"cell_type":"code","source":["import pandas as pd\nfrom os import listdir\nfrom os.path import join, basename\nimport struct\nimport pickle\nimport json\nimport os\nfrom scipy import misc\nimport datetime as dt\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline as ml_Pipeline\nfrom pyspark.ml.feature import StringIndexer\nfrom math import ceil\n# import matplotlib.pyplot as plt\n# %matplotlib inline"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# %pylab inline\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.nn.initialization_method import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\nfrom bigdl.dataset.transformer import *\nfrom bigdl.dataset import mnist\nfrom bigdl.transform.vision.image import *\nfrom zoo.pipeline.nnframes.nn_image_reader import *\nfrom zoo.pipeline.nnframes.nn_image_transformer import *\nfrom zoo.pipeline.nnframes.nn_classifier import *\nfrom zoo.common.nncontext import *\nimport urllib\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["\ndef t(input_T):\n    \"\"\"\n    Helper function for building Inception layers. Transforms a list of numbers to a dictionary with ascending keys \n    and 0 appended to the front. Ignores dictionary inputs. \n    \n    :param input_T: either list or dict\n    :return: dictionary with ascending keys and 0 appended to front {0: 0, 1: realdata_1, 2: realdata_2, ...}\n    \"\"\"    \n    if type(input_T) is list:\n        # insert 0 into first index spot, such that the real data starts from index 1\n        temp = [0]\n        temp.extend(input_T)\n        return dict(enumerate(temp))\n    # if dictionary, return it back\n    return input_T"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def inception_layer_v1(input_size, config, name_prefix=\"\"):\n    concat = Concat(2)\n    conv1 = Sequential()\n    conv1.add(SpatialConvolution(input_size, config[1][1], 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(),bias_init_method=Zeros())\n              .set_name(name_prefix + \"1x1\"))\n    conv1.add(ReLU(True).set_name(name_prefix + \"relu_1x1\"))\n    concat.add(conv1)\n    conv3 = Sequential()\n    conv3.add(SpatialConvolution(input_size, config[2][1], 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(name_prefix + \"3x3_reduce\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3_reduce\"))\n    conv3.add(SpatialConvolution(config[2][1], config[2][2], 3, 3, 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(name_prefix + \"3x3\"))\n    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3\"))\n    concat.add(conv3)\n    conv5 = Sequential()\n    conv5.add(SpatialConvolution(input_size, config[3][1], 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(name_prefix + \"5x5_reduce\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5_reduce\"))\n    conv5.add(SpatialConvolution(config[3][1], config[3][2], 5, 5, 1, 1, 2, 2)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(name_prefix + \"5x5\"))\n    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5\"))\n    concat.add(conv5)\n    pool = Sequential()\n    pool.add(SpatialMaxPooling(3, 3, 1, 1, 1, 1, to_ceil=True).set_name(name_prefix + \"pool\"))\n    pool.add(SpatialConvolution(input_size, config[4][1], 1, 1, 1, 1)\n             .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n             .set_name(name_prefix + \"pool_proj\"))\n    pool.add(ReLU(True).set_name(name_prefix + \"relu_pool_proj\"))\n    concat.add(pool).set_name(name_prefix + \"output\")\n    return concat"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def inception_v1_no_aux_classifier(class_num, has_dropout=True):\n    model = Sequential()\n    model.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(\"conv1/7x7_s2\"))\n    model.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n    model.add(SpatialConvolution(64, 64, 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(\"conv2/3x3_reduce\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n    model.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(\"conv2/3x3\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n    model.add(inception_layer_v1(192, t([t([64]), t(\n        [96, 128]), t([16, 32]), t([32])]), \"inception_3a/\"))\n    model.add(inception_layer_v1(256, t([t([128]), t(\n        [128, 192]), t([32, 96]), t([64])]), \"inception_3b/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(inception_layer_v1(480, t([t([192]), t(\n        [96, 208]), t([16, 48]), t([64])]), \"inception_4a/\"))\n    model.add(inception_layer_v1(512, t([t([160]), t(\n        [112, 224]), t([24, 64]), t([64])]), \"inception_4b/\"))\n    model.add(inception_layer_v1(512, t([t([128]), t(\n        [128, 256]), t([24, 64]), t([64])]), \"inception_4c/\"))\n    model.add(inception_layer_v1(512, t([t([112]), t(\n        [144, 288]), t([32, 64]), t([64])]), \"inception_4d/\"))\n    model.add(inception_layer_v1(528, t([t([256]), t(\n        [160, 320]), t([32, 128]), t([128])]), \"inception_4e/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(inception_layer_v1(832, t([t([256]), t(\n        [160, 320]), t([32, 128]), t([128])]), \"inception_5a/\"))\n    model.add(inception_layer_v1(832, t([t([384]), t(\n        [192, 384]), t([48, 128]), t([128])]), \"inception_5b/\"))\n    model.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n    if has_dropout:\n        model.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n    model.add(View([1024], num_input_dims=3))\n    model.add(Linear(1024, class_num)\n              .set_init_method(weight_init_method=Xavier(), bias_init_method=Zeros())\n              .set_name(\"loss3/classifier\"))\n    model.add(LogSoftMax().set_name(\"loss3/loss3\"))\n    model.reset()\n    return model"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["def Inception_v1(class_num):\n    model = Sequential()\n    model.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False).set_name(\"conv1/7x7_s2\"))\n    model.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n    model.add(SpatialConvolution(64, 64, 1, 1, 1, 1).set_name(\"conv2/3x3_reduce\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n    model.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1).set_name(\"conv2/3x3\"))\n    model.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n    model.add(inception_layer_v1(192, scala_T([scala_T([64]), scala_T(\n         [96, 128]), scala_T([16, 32]), scala_T([32])]), \"inception_3a/\"))\n    model.add(inception_layer_v1(256, scala_T([scala_T([128]), scala_T(\n         [128, 192]), scala_T([32, 96]), scala_T([64])]), \"inception_3b/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(inception_layer_v1(480, scala_T([scala_T([192]), scala_T(\n         [96, 208]), scala_T([16, 48]), scala_T([64])]), \"inception_4a/\"))\n    model.add(inception_layer_v1(512, scala_T([scala_T([160]), scala_T(\n         [112, 224]), scala_T([24, 64]), scala_T([64])]), \"inception_4b/\"))\n    model.add(inception_layer_v1(512, scala_T([scala_T([128]), scala_T(\n         [128, 256]), scala_T([24, 64]), scala_T([64])]), \"inception_4c/\"))\n    model.add(inception_layer_v1(512, scala_T([scala_T([112]), scala_T(\n         [144, 288]), scala_T([32, 64]), scala_T([64])]), \"inception_4d/\"))\n    model.add(inception_layer_v1(528, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_4e/\"))\n    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n    model.add(inception_layer_v1(832, scala_T([scala_T([256]), scala_T(\n         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_5a/\"))\n    model.add(inception_layer_v1(832, scala_T([scala_T([384]), scala_T(\n         [192, 384]), scala_T([48, 128]), scala_T([128])]), \"inception_5b/\"))\n    model.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n    model.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n    model.add(View([1024], num_input_dims=3))\n    model.add(Linear(1024, class_num).set_name(\"loss3/classifier\"))\n    model.add(LogSoftMax().set_name(\"loss3/loss3\"))\n    model.reset()\n    return model"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Download the images from Amazon s3\n\nMake sure you have AWS command line interface to recursively download all images in s3 folder. You can set up aws cli from this link: http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html"],"metadata":{}},{"cell_type":"code","source":["import urllib\nfrom os import path\nMODEL_ROOT = \"/mnt/nobigdl/vegnonveg/python/inception_v1/models/\"\ncheckpoint_path = path.join(MODEL_ROOT, \"checkpoints\")\n\n# if not path.isdir(local_folder):\n#   os.system('aws s3 cp --recursive s3://vegnonveg/vegnonveg-fewsamples %s' % local_folder)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Read images to parquet fileand load to Spark as Image dataframe\n\nsave data to parquet files and load to spark. Add label to each image."],"metadata":{}},{"cell_type":"code","source":["DATA_ROOT = \"/mnt/nobigdl/vegnonveg/python/inception_v1/sample_images/\"\nsample_path = DATA_ROOT + 'vegnonveg-fewsamples/'\nlabel_path = DATA_ROOT + 'vegnonveg-samples_labels.csv'\nparquet_path = DATA_ROOT + 'sample_parquet/'\ndbutils.fs.rm(parquet_path, True)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#intializa bigdl\ninit_engine()\nredire_spark_logs()\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# This only runs at the first time to generate parquet files\nimage_frame = NNImageReader.readImages(sample_path, sc, minParitions=32)\n# save dataframe to parquet files\n# image_frame.write.parquet(parquet_path)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# load parquet file into spark cluster\nimport time\nstart = time.time()\n# image_raw_DF = sqlContext.read.parquet(parquet_path)\nend = time.time()\nprint(\"Load data time is: \" + str(end-start) + \" seconds\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# create label dataframe\nlabel_raw_DF = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"mode\", \"DROPMALFORMED\")\\\n    .load(label_path)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# create image data dataframe\nget_name = udf(lambda row: row[0].split(\"/\")[-1], StringType())\nimageDF = image_frame.withColumn(\"image_name\", get_name(\"image\"))\n# imageDF.show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nfrom pyspark.sql.functions import col, rand\n# image dataframe join with labels\ndataDF = imageDF.join(label_raw_DF, imageDF.image_name==label_raw_DF.obs_uid, \"inner\").select(\"image\", \"image_name\", \"item_name\")\n# only use samples whose label count > 100\nitems = dataDF.groupBy(\"item_name\").count().filter(\"count > 100\").select(\"item_name\")\nindexer = StringIndexer(inputCol=\"item_name\", outputCol=\"label\")\nlabels = indexer.fit(items).transform(items).withColumn(\"label\", (col(\"label\") + 1).cast(\"float\"))\nfilteredDF = dataDF.join(labels, \"item_name\", \"inner\").select(\"image\", \"image_name\", \"label\").orderBy(rand())\nn_classes = labels.count()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Do Train/Test Split and preprocessing\nSplit Train/Test split with some ratio and preprocess images."],"metadata":{}},{"cell_type":"code","source":["data = filteredDF.randomSplit([0.9, 0.1], seed=10)\ntrain_image = data[0]\nval_image = data[1]"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["IMAGE_SIZE = 224\n\ntrain_transformer = NNImageTransformer(\n    Pipeline([Resize(256, 256), CenterCrop(IMAGE_SIZE, IMAGE_SIZE),\n              ChannelNormalize(123.0, 117.0, 104.0, 1.0, 1.0, 1.0),\n              MatToTensor()])\n).setInputCol(\"image\").setOutputCol(\"features\")\n\ntrain_data = train_transformer.transform(train_image)\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["train_size = train_image.count()\ntrain_size"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["val_transformer = NNImageTransformer(\n    Pipeline([Resize(256,256),\n              CenterCrop(IMAGE_SIZE, IMAGE_SIZE),\n              ChannelNormalize(123.0, 117.0, 104.0, 1.0, 1.0, 1.0),\n              MatToTensor(to_rgb=True)]\n            )\n).setInputCol(\"image\").setOutputCol(\"features\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["test_data = val_transformer.transform(val_image)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["## Define Model"],"metadata":{}},{"cell_type":"code","source":["model_path = \"dbfs:\" + MODEL_ROOT + \"bvlc_googlenet.caffemodel\"\ndef_path = \"dbfs:\" + MODEL_ROOT + \"deploy_transfer.prototxt\"\nmodel = Model.load_caffe_model(def_path, model_path)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Parameters\nlearning_rate = 0.2\n# parameters for \nbatch_size = 64 #depends on dataset\nno_epochs = 40 #stop when validation accuracy doesn't improve anymore"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Network Parameters\npreTrainedNNModel = NNModel(model, [3,224,224]).setPredictionCol(\"embedding\").setBatchSize(batch_size)\nlrModel = Sequential().add(View([1024])).add(Linear(1024, n_classes)).add(LogSoftMax())"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["criterion = ClassNLLCriterion()\niterations = int(ceil(float(train_size) / batch_size))\noptim = SGD(learningrate=learning_rate, learningrate_decay=0.0,\n                    momentum=0.9, dampening=0.0, nesterov=False,\n                    leaningrate_schedule=Poly(0.5, iterations))\nclassifier = NNClassifier(lrModel, criterion, [1024])\\\n    .setBatchSize(batch_size)\\\n    .setMaxEpoch(no_epochs)\\\n    .setLearningRate(learning_rate)\\\n    .setFeaturesCol(\"embedding\")\npipeline = ml_Pipeline(stages=[preTrainedNNModel, classifier])\nstart = time.time()\ntrained_model = pipeline.fit(train_data)\nend = time.time()\nprint(\"Optimization Done.\")\nprint(\"Training time is: %s seconds\" % str(end-start))\n# + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["throughput = train_size * no_epochs / (end - start)\nprint(\"Average throughput is: %s\" % str(throughput))"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["#predict\n# predict_model = trained_model.setBatchSize(batch_size)\npredictionDF = trained_model.transform(test_data)\npredictionDF.show()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["num_preds = 1\npreds = predictionDF.select(\"label\", \"prediction\").take(num_preds)\nfor idx in range(num_preds):\n#    true_label = str(map_to_label(map_groundtruth_label(truth[idx].label)))\n    true_label = preds[idx][0]\n    pred_label = preds[idx][1]\n    print(str(idx + 1) +')'+ 'Ground Truth label: '+ str(true_label))\n    print(str(idx + 1) + ')'+ 'Predicted label: '+ str(pred_label))\n    print(\"correct\" if true_label == pred_label else \"wrong\")"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["'''\nMeasure Test Accuracy w/Test Set\n'''\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictionDF)\nprint(\"Accuracy = %g \" % accuracy)"],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"name":"vegnonveg-fulltraining-nnframe-transfer","notebookId":2948019328317446},"nbformat":4,"nbformat_minor":0}
